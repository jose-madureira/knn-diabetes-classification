{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# Classificação de Diabetes com KNN\n",
        "\n",
        "Este notebook estrutura o desenvolvimento de um modelo de classificação utilizando o algoritmo K-Nearest Neighbors (KNN) para a previsão da presença de diabetes, com base no conjunto de dados Pima Indians Diabetes. O trabalho segue um fluxo completo de projeto em aprendizado de máquina, cobrindo desde a preparação dos dados até a avaliação crítica do desempenho do modelo, com ênfase em rigor metodológico e reprodutibilidade dos resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "libs-install-md"
      },
      "source": [
        "### 1. Instalação e Importação de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wxm5YvYapza"
      },
      "outputs": [],
      "source": [
        "# Instalação das bibliotecas necessárias\n",
        "# %%capture evita que as saídas da instalação poluam o notebook, mantendo-o limpo.\n",
        "%%capture\n",
        "%pip install numpy pandas matplotlib seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "libs-import-code"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn para modelagem e pré-processamento\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Modelos adicionais para comparação (importados apenas se forem de fato utilizados no projeto)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Configurações globais para visualização (opcional, mas recomendado para padronizar a estética dos gráficos)\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6) # Tamanho padrão para figuras\n",
        "plt.rcParams['axes.titlesize'] = 16    # Tamanho da fonte do título dos eixos\n",
        "plt.rcParams['axes.labelsize'] = 12    # Tamanho da fonte dos rótulos dos eixos\n",
        "plt.rcParams['xtick.labelsize'] = 10   # Tamanho da fonte dos ticks do eixo X\n",
        "plt.rcParams['ytick.labelsize'] = 10   # Tamanho da fonte dos ticks do eixo Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-overview-md"
      },
      "source": [
        "### 2. Carregamento e Visão Geral dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data-load-code"
      },
      "outputs": [],
      "source": [
        "# Carrega o dataset a partir de um arquivo CSV armazenado localmente.\n",
        "df = pd.read_csv('data/diabetes.csv')\n",
        "\n",
        "# Exibe as cinco primeiras entradas da base para verificação da estrutura e conteúdo dos dados.\n",
        "print(\"Primeiras 5 linhas do dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Exibe a dimensão da base de dados (número de registros e atributos disponíveis).\n",
        "print(\"\\nFormato do dataset (linhas, colunas):\", df.shape)\n",
        "\n",
        "# Mostra os tipos de dados, nomes das colunas e presença de valores ausentes.\n",
        "print(\"\\nInformações sobre as colunas e tipos de dados:\")\n",
        "df.info()\n",
        "\n",
        "# Resume estatísticas básicas das variáveis numéricas (média, desvio, quartis etc.).\n",
        "print(\"\\nEstatísticas descritivas das variáveis numéricas:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Verifica a distribuição da variável alvo, útil para identificar desbalanceamento.\n",
        "print(\"\\nContagem de valores na variável alvo 'Outcome':\")\n",
        "print(df['Outcome'].value_counts())\n",
        "\n",
        "# Etapa exploratória essencial para conhecer a estrutura e equilíbrio dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-prep-md"
      },
      "source": [
        "### 3. Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "missing-values-code"
      },
      "outputs": [],
      "source": [
        "# Define as colunas onde o valor zero representa ausência de dado e não um valor válido.\n",
        "columns_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "\n",
        "# Substitui zeros por NaN para permitir tratamento adequado de dados ausentes.\n",
        "df[columns_with_zeros] = df[columns_with_zeros].replace(0, np.nan)\n",
        "\n",
        "# Verifica quantos valores ausentes existem após a substituição dos zeros.\n",
        "print(\"Valores nulos após substituição de 0 por NaN:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Preenche valores ausentes com a média nas colunas de distribuição simétrica.\n",
        "for col in ['Glucose', 'BloodPressure', 'BMI']:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].mean())\n",
        "        print(f\"Valores ausentes em '{col}' preenchidos com a média.\")\n",
        "\n",
        "# Preenche com a mediana nas colunas com assimetria ou presença de outliers.\n",
        "for col in ['SkinThickness', 'Insulin']:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "        print(f\"Valores ausentes em '{col}' preenchidos com a mediana.\")\n",
        "\n",
        "# Verifica se todas as imputações foram concluídas corretamente.\n",
        "print(\"\\nContagem de valores nulos após a imputação final:\")\n",
        "print(df[columns_with_zeros].isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eda-md"
      },
      "source": [
        "### 4. Análise Exploratória de Dados (EDA) Aprofundada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "histograms-code"
      },
      "outputs": [],
      "source": [
        "# Gera histogramas para todas as variáveis numéricas do dataset, permitindo observar a distribuição, presença de assimetrias e possíveis outliers.\n",
        "df.hist(figsize=(15, 10), bins=10)\n",
        "\n",
        "# Define um título geral para a grade de subplots gerada.\n",
        "plt.suptitle('Histogramas das Variáveis do Dataset', y=1.02)\n",
        "\n",
        "# Ajusta o layout para que o título e os gráficos não se sobreponham.\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
        "\n",
        "# Exibe os gráficos.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "corr-matrix-code"
      },
      "outputs": [],
      "source": [
        "# Define o tamanho da figura para facilitar a leitura do mapa de calor.\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Gera a matriz de correlação com anotação dos valores e esquema de cores.\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "\n",
        "# Adiciona um título ao gráfico para contextualizar a visualização.\n",
        "plt.title('Matriz de Correlação das Variáveis')\n",
        "\n",
        "# Exibe o gráfico na tela.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eda-bivariate-code"
      },
      "outputs": [],
      "source": [
        "# Define as variáveis numéricas que serão analisadas por diagnóstico.\n",
        "numeric_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
        "                    'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
        "\n",
        "# Cria a figura com tamanho apropriado para os subplots.\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Itera sobre cada variável para gerar os box plots segmentados por Outcome.\n",
        "for i, feature in enumerate(numeric_features):\n",
        "    # Define a posição do subplot na grade (3 linhas x 3 colunas).\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "\n",
        "    # Cria o box plot da variável atual comparando grupos com e sem diabetes.\n",
        "    sns.boxplot(x='Outcome', y=feature, data=df, palette='viridis', ax=ax, hue='Outcome', legend=False)\n",
        "\n",
        "    # Adiciona o título individual para cada gráfico.\n",
        "    plt.title(f'Distribuição de {feature} por Outcome')\n",
        "\n",
        "    # Define o rótulo do eixo X com descrição textual.\n",
        "    plt.xlabel('Diagnóstico de Diabetes')\n",
        "\n",
        "    # Define o rótulo do eixo Y com o nome da variável analisada.\n",
        "    plt.ylabel(feature)\n",
        "\n",
        "    # Substitui os valores binários por rótulos interpretáveis no eixo X.\n",
        "    ax.set_xticks([0, 1])\n",
        "    ax.set_xticklabels(['Não Diabético', 'Diabético'])\n",
        "\n",
        "# Ajusta o layout da figura para evitar sobreposições.\n",
        "plt.tight_layout()\n",
        "\n",
        "# Exibe todos os box plots.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6KvQo2galzB"
      },
      "outputs": [],
      "source": [
        "# Cria nova figura para visualização da densidade das variáveis por grupo.\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Itera sobre as mesmas variáveis para gerar os violin plots.\n",
        "for i, feature in enumerate(numeric_features):\n",
        "    # Define a posição do subplot na grade.\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "\n",
        "    # Gera o violin plot que combina distribuição com medidas de tendência central.\n",
        "    sns.violinplot(x='Outcome', y=feature, data=df, palette='magma', ax=ax, hue='Outcome', legend=False)\n",
        "\n",
        "    # Título do gráfico com a variável analisada.\n",
        "    plt.title(f'Densidade de {feature} por Outcome')\n",
        "\n",
        "    # Define rótulo explicativo do eixo X.\n",
        "    plt.xlabel('Diagnóstico de Diabetes')\n",
        "\n",
        "    # Define o eixo Y com o nome da variável.\n",
        "    plt.ylabel(feature)\n",
        "\n",
        "    # Aplica rótulos descritivos para os grupos.\n",
        "    ax.set_xticks([0, 1])\n",
        "    ax.set_xticklabels(['Não Diabético', 'Diabético'])\n",
        "\n",
        "# Ajusta os elementos da figura.\n",
        "plt.tight_layout()\n",
        "\n",
        "# Exibe todos os violin plots.\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-prep-model-md"
      },
      "source": [
        "### 5. Preparação dos Dados para o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "split-xy-code"
      },
      "outputs": [],
      "source": [
        "# Separa as variáveis explicativas (features) removendo a variável alvo 'Outcome'.\n",
        "X = df.drop('Outcome', axis=1)\n",
        "\n",
        "# Define 'Outcome' como variável alvo, que indica presença (1) ou ausência (0) de diabetes.\n",
        "y = df['Outcome']\n",
        "\n",
        "# Instancia o objeto StandardScaler para normalização das variáveis.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Aplica a padronização nas features, ajustando média para 0 e desvio padrão para 1.\n",
        "# Essa etapa é essencial para algoritmos sensíveis à escala, como o KNN.\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# (Opcional) Conversão para DataFrame para visualização dos dados normalizados.\n",
        "# print(\"\\nPrimeiras 5 linhas dos dados escalonados:\")\n",
        "# print(X_scaled_df.head())\n",
        "\n",
        "# Separa os dados em treino (70%) e teste (30%), preservando a proporção das classes com stratify.\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.30, random_state=101, stratify=y\n",
        ")\n",
        "\n",
        "# Exibe o formato do conjunto de treino após a divisão.\n",
        "print(f\"\\nShape do conjunto de treino: {X_train_scaled.shape}\")\n",
        "\n",
        "# Exibe o formato do conjunto de teste após a divisão.\n",
        "print(f\"Shape do conjunto de teste: {X_test_scaled.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-training-md"
      },
      "source": [
        "### 6. Treinamento e Otimização do Modelo KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gridsearch-code"
      },
      "outputs": [],
      "source": [
        "# Define a grade de valores de k (n_neighbors) a serem testados no modelo.\n",
        "param_grid = {'n_neighbors': np.arange(1, 26)}  # Testa k de 1 a 25.\n",
        "\n",
        "# Instancia o classificador KNN sem configurar k ainda.\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Configura o GridSearchCV para buscar o melhor valor de k usando 5-fold cross-validation.\n",
        "# scoring='accuracy' define que a métrica de avaliação será acurácia.\n",
        "# n_jobs=-1 ativa o uso de todos os núcleos da CPU (execução paralela).\n",
        "knn_cv = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "\n",
        "# Inicia o processo de busca pelos melhores hiperparâmetros no conjunto de treino escalado.\n",
        "print(\"Iniciando busca de hiperparâmetros com GridSearchCV...\")\n",
        "knn_cv.fit(X_train_scaled, y_train)\n",
        "print(\"Busca de hiperparâmetros concluída.\")\n",
        "\n",
        "# Exibe os melhores hiperparâmetros encontrados após a validação cruzada.\n",
        "print(f\"\\nMelhores parâmetros encontrados: {knn_cv.best_params_}\")\n",
        "print(f\"Melhor acurácia (média da validação cruzada no treino): {knn_cv.best_score_:.4f}\")\n",
        "\n",
        "# Extrai o melhor modelo treinado com o valor ideal de k encontrado.\n",
        "best_knn_model = knn_cv.best_estimator_\n",
        "\n",
        "# Converte os resultados detalhados da validação cruzada em DataFrame para visualização.\n",
        "results = pd.DataFrame(knn_cv.cv_results_)\n",
        "\n",
        "# Cria gráfico de linha para visualizar o desempenho médio por valor de k.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(results['param_n_neighbors'], results['mean_test_score'], marker='o', linestyle='-')\n",
        "\n",
        "# Adiciona título e rótulos aos eixos do gráfico.\n",
        "plt.title('Acurácia Média da Validação Cruzada vs. K Value')\n",
        "plt.xlabel('K Value (n_neighbors)')\n",
        "plt.ylabel('Acurácia Média (Validação Cruzada)')\n",
        "\n",
        "# Ajusta os valores do eixo X para facilitar leitura.\n",
        "plt.xticks(np.arange(1, 26, 2))  # Mostra um tick a cada 2 valores.\n",
        "\n",
        "# Adiciona grade ao gráfico para melhor leitura visual.\n",
        "plt.grid(True)\n",
        "\n",
        "# Exibe o gráfico.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-eval-md"
      },
      "source": [
        "### 7. Avaliação do Modelo Otimizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "classification-report-code"
      },
      "outputs": [],
      "source": [
        "# Realiza as previsões no conjunto de teste usando o modelo KNN otimizado.\n",
        "y_pred_optimized = best_knn_model.predict(X_test_scaled)\n",
        "\n",
        "# Exibe o relatório de classificação com métricas detalhadas:\n",
        "# precisão, recall, F1-score e suporte para cada classe.\n",
        "print(\"\\n--- Relatório de Classificação para o Modelo KNN Otimizado ---\")\n",
        "print(classification_report(y_test, y_pred_optimized))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "confusion-matrix-code"
      },
      "outputs": [],
      "source": [
        "# Calcula a matriz de confusão comparando os rótulos reais com os previstos.\n",
        "cm_optimized = confusion_matrix(y_test, y_pred_optimized)\n",
        "\n",
        "# Define o tamanho da figura para visualização da matriz.\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "# Gera o heatmap da matriz de confusão com anotações numéricas.\n",
        "sns.heatmap(cm_optimized, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Não Diabético', 'Diabético'],\n",
        "            yticklabels=['Não Diabético', 'Diabético'])\n",
        "\n",
        "# Define o rótulo do eixo X como \"Previsão\".\n",
        "plt.xlabel('Previsão')\n",
        "\n",
        "# Define o rótulo do eixo Y como \"Real\".\n",
        "plt.ylabel('Real')\n",
        "\n",
        "# Adiciona o título ao gráfico para contextualizar.\n",
        "plt.title('Matriz de Confusão (KNN Otimizado)')\n",
        "\n",
        "# Exibe a matriz de confusão na tela.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-comparison-md"
      },
      "source": [
        "### 8. (Opcional) Comparação com Outros Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model-comparison-code"
      },
      "outputs": [],
      "source": [
        "# Inicia a comparação exibindo o título para a Regressão Logística.\n",
        "print(\"\\n--- Comparação com Regressão Logística ---\")\n",
        "\n",
        "# Instancia o modelo de Regressão Logística com solver 'liblinear' (adequado para conjuntos pequenos/médios).\n",
        "log_model = LogisticRegression(solver='liblinear', random_state=101)\n",
        "\n",
        "# Treina o modelo de regressão logística com os dados de treino normalizados.\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Realiza as previsões no conjunto de teste.\n",
        "y_pred_log = log_model.predict(X_test_scaled)\n",
        "\n",
        "# Exibe as métricas de desempenho da regressão logística.\n",
        "print(\"Relatório de Classificação (Regressão Logística):\")\n",
        "print(classification_report(y_test, y_pred_log))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3v6zpkkalzD"
      },
      "outputs": [],
      "source": [
        "# Inicia a avaliação da Árvore de Decisão.\n",
        "print(\"\\n--- Comparação com Árvore de Decisão ---\")\n",
        "\n",
        "# Instancia o modelo de árvore com semente fixa para reprodutibilidade.\n",
        "tree_model = DecisionTreeClassifier(random_state=101)\n",
        "\n",
        "# Treina a árvore com os dados de treino normalizados.\n",
        "tree_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Realiza as previsões no conjunto de teste.\n",
        "y_pred_tree = tree_model.predict(X_test_scaled)\n",
        "\n",
        "# Exibe as métricas da árvore de decisão.\n",
        "print(\"Relatório de Classificação (Árvore de Decisão):\")\n",
        "print(classification_report(y_test, y_pred_tree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6ZmBlvGalzD"
      },
      "outputs": [],
      "source": [
        "# Cria um DataFrame com as principais métricas para cada modelo avaliado.\n",
        "results_df = pd.DataFrame({\n",
        "    'Modelo': ['KNN Otimizado', 'Regressão Logística', 'Árvore de Decisão'],\n",
        "\n",
        "    # Calcula a acurácia de cada modelo no conjunto de teste.\n",
        "    'Acurácia': [accuracy_score(y_test, y_pred_optimized),\n",
        "                 accuracy_score(y_test, y_pred_log),\n",
        "                 accuracy_score(y_test, y_pred_tree)],\n",
        "\n",
        "    # Extrai o F1-score da classe 1 (diabético) de cada modelo.\n",
        "    'F1-score (Classe 1 - Diabético)': [\n",
        "        classification_report(y_test, y_pred_optimized, output_dict=True)['1']['f1-score'],\n",
        "        classification_report(y_test, y_pred_log, output_dict=True)['1']['f1-score'],\n",
        "        classification_report(y_test, y_pred_tree, output_dict=True)['1']['f1-score']\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Exibe o DataFrame com as métricas arredondadas.\n",
        "print(\"\\nComparação de Métricas Chave entre Modelos:\")\n",
        "print(results_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBmgdP-FalzD"
      },
      "outputs": [],
      "source": [
        "# Gera gráfico de barras para comparar visualmente a acurácia dos modelos.\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Cria o gráfico com cores da paleta 'viridis' para facilitar distinção entre modelos.\n",
        "sns.barplot(x='Modelo', y='Acurácia', data=results_df, palette='viridis', hue='Modelo', legend=False)\n",
        "\n",
        "# Define o título e rótulo do eixo Y.\n",
        "plt.title('Comparação de Acurácia entre Modelos')\n",
        "plt.ylabel('Acurácia')\n",
        "\n",
        "# Limita o eixo Y para focar na faixa relevante das acurácias obtidas.\n",
        "plt.ylim(0.7, 0.85)\n",
        "\n",
        "# Exibe o gráfico.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "error-analysis-md"
      },
      "source": [
        "### 9. Análise de Erros (Opcional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "error-details-code"
      },
      "outputs": [],
      "source": [
        "# Cria um DataFrame com os rótulos reais, previstos e um indicador de erro.\n",
        "results_df = pd.DataFrame({\n",
        "    'Real': y_test,                      # Valor verdadeiro da classe.\n",
        "    'Previsto': y_pred_optimized,       # Valor previsto pelo modelo.\n",
        "    'Erro': y_test != y_pred_optimized  # Booleano indicando erro de previsão.\n",
        "}, index=y_test.index)  # Mantém o índice original para permitir ligação com os dados completos.\n",
        "\n",
        "# Recupera os dados originais (não normalizados) do conjunto de teste com base no índice.\n",
        "original_X_test = X.loc[y_test.index]\n",
        "\n",
        "# Combina os dados originais com os resultados de previsão para análise conjunta.\n",
        "analysis_df = pd.concat([original_X_test, results_df], axis=1)\n",
        "\n",
        "# Filtra os casos de Falsos Negativos: Real = 1, Previsto = 0.\n",
        "print(\"\\n--- Falsos Negativos (Modelo previu 0, mas o Real era 1) ---\")\n",
        "false_negatives = analysis_df[(analysis_df['Real'] == 1) & (analysis_df['Previsto'] == 0)]\n",
        "\n",
        "# Exibe as primeiras 5 ocorrências de falsos negativos.\n",
        "print(false_negatives.head())\n",
        "\n",
        "# Exibe o total de instâncias classificadas incorretamente como negativas.\n",
        "print(f\"\\nTotal de Falsos Negativos: {len(false_negatives)}\")\n",
        "\n",
        "# Calcula a média das variáveis numéricas dos casos de FN para identificar padrões.\n",
        "print(\"\\nMédia das características para Falsos Negativos:\")\n",
        "print(false_negatives[numeric_features].mean())\n",
        "\n",
        "# Filtra os casos de Falsos Positivos: Real = 0, Previsto = 1.\n",
        "print(\"\\n--- Falsos Positivos (Modelo previu 1, mas o Real era 0) ---\")\n",
        "false_positives = analysis_df[(analysis_df['Real'] == 0) & (analysis_df['Previsto'] == 1)]\n",
        "\n",
        "# Exibe as primeiras 5 ocorrências de falsos positivos.\n",
        "print(false_positives.head())\n",
        "\n",
        "# Exibe o total de instâncias classificadas incorretamente como positivas.\n",
        "print(f\"\\nTotal de Falsos Positivos: {len(false_positives)}\")\n",
        "\n",
        "# Calcula a média das variáveis numéricas dos casos de FP para possíveis padrões de confusão.\n",
        "print(\"\\nMédia das características para Falsos Positivos:\")\n",
        "print(false_positives[numeric_features].mean())\n",
        "\n",
        "# A análise dos erros mostra que os falsos negativos tendem a ocorrer em casos com valores limítrofes de glicose ou BMI,\n",
        "# indicando possível subdiagnóstico em pacientes de risco intermediário.\n",
        "# Já os falsos positivos sugerem sobreposição de perfis entre classes, com o modelo confundindo padrões saudáveis com indicativos de diabetes.\n",
        "# Esses achados reforçam a importância de revisar variáveis, limiares e considerar modelos mais sensíveis à ambiguidade entre classes."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
